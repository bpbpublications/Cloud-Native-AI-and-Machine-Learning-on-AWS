{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Update IAM to add permissions\n",
    "Before we can execute the code below, we need to ensure our execution role has the permissions to use the AI services. We need to add the policy to the SageMaker studio execution role. Please follow the instructions in the sub-section **Setting up IAM permissions** from the section **Adding sensory cognition to your applications** in Chapter 10 of the book before proceeding to execute the rest of the cells below."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the libraries we need\n",
    "import boto3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import io\n",
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import warnings\n",
    "from IPython.display import display\n",
    "from time import strftime, gmtime\n",
    "from sagemaker import get_execution_role\n",
    "from datetime import datetime, timezone\n",
    "\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# declare the boto3 handles for each AI service\n",
    "transcribe = boto3.client(\"transcribe\")\n",
    "rekognition = boto3.client(\"rekognition\")\n",
    "translate = boto3.client(\"translate\")\n",
    "polly = boto3.client(\"polly\")\n",
    "comprehend = boto3.client(\"comprehend\")\n",
    "# Amazon S3 (S3) client\n",
    "s3 = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Amazon Transcribe for automatic speech recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bucket = 'your-S3-bucket'\n",
    "prefix = 'aiml-book/chapter10'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First let us list our audio files and then upload them to the S3 bucket\n",
    "# we will use the example audio file we provided with the repo\n",
    "audio_dir = 'input/audio-recordings'\n",
    "for sdir, drs, fls in os.walk(audio_dir):\n",
    "    for file in fls:\n",
    "        s3.upload_file(os.path.join(sdir, file), bucket, prefix+'/transcribe/'+ os.path.join(sdir, file))\n",
    "        uri = \"s3://\" + bucket + '/'+prefix+'/transcribe/' + os.path.join(sdir, file)\n",
    "        print(\"Uploaded to: \" + uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the current time\n",
    "now = datetime.now()\n",
    "time_now = now.strftime(\"%H.%M.%S\")\n",
    "job = 'transcribe-test-'+time_now\n",
    "# start the transcription job\n",
    "try:\n",
    "    transcribe.start_transcription_job(\n",
    "            TranscriptionJobName=job,\n",
    "            LanguageCode='en-US',\n",
    "            Media={\"MediaFileUri\": uri},\n",
    "            Settings={'MaxSpeakerLabels': 2, 'ShowSpeakerLabels': True}\n",
    "            )\n",
    "        \n",
    "    time.sleep(2)    \n",
    "    print(transcribe.get_transcription_job(TranscriptionJobName=job)['TranscriptionJob']['TranscriptionJobStatus'])\n",
    "except Exception as e:\n",
    "    print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get transcription results\n",
    "Our job will take about 2 to 3 minutes to complete. You can also lookup the status of the job in Amazon Transcribe console by going to https://us-east-1.console.aws.amazon.com/transcribe/home?region=us-east-1#jobs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an output transcripts directory\n",
    "dr = os.getcwd()+'/output-transcripts'\n",
    "if not os.path.exists(dr):\n",
    "    os.makedirs(dr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Our transcript is in a presigned URL in Transcribe's S3 bucket, let us download it and get the text we need\n",
    "import urllib.request\n",
    "response = transcribe.get_transcription_job(\n",
    "    TranscriptionJobName=job \n",
    ")\n",
    "out_url = response['TranscriptionJob']['Transcript']['TranscriptFileUri']\n",
    "infile = job+'-output.json'\n",
    "urllib.request.urlretrieve(out_url, infile)\n",
    "# declare an output file to store the transcripts\n",
    "outfile = 'output-transcripts/'+job+'.txt'\n",
    "with open(infile, 'rb') as t_in:\n",
    "    full = json.load(t_in)\n",
    "    entire_transcript = full[\"results\"][\"transcripts\"]\n",
    "    lines = str(entire_transcript).split('. ')\n",
    "    i = 0\n",
    "    for line in lines:\n",
    "        i += 1\n",
    "        print(\"Line \"+str(i)+\": \" + line)\n",
    "    # write the transcript to an output file\n",
    "    with open(outfile, 'w') as out:\n",
    "        out.write(str(lines))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Amazon Rekognition for computer vision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Lets use the Python image processing Pillow library\n",
    "from PIL import Image\n",
    "img = Image.open('./input/images/puppy-image.jpg')\n",
    "display(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now use Amazon Rekognition APIs to perform some computer vision tasks without any ML training whatsoever. For a full list of Python APIs for Rekognition refer to - https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/rekognition.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Detect Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First upload image to S3 bucket\n",
    "input_dir = 'input/images'\n",
    "prefix_uris = []\n",
    "for sdir, drs, fls in os.walk(input_dir):\n",
    "    for file in fls:\n",
    "        s3.upload_file(os.path.join(sdir, file), bucket, prefix+'/rekognition/'+ os.path.join(sdir, file))\n",
    "        uri = \"s3://\" + bucket + '/'+prefix+'/rekognition/' + os.path.join(sdir, file)\n",
    "        prefix_uri = prefix+'/rekognition/' + os.path.join(sdir, file)\n",
    "        prefix_uris.append(prefix_uri)\n",
    "        print(\"Uploaded to: \" + uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Detect Labels\n",
    "for prefix_uri in prefix_uris:\n",
    "    response = rekognition.detect_labels(\n",
    "        Image={\n",
    "            'S3Object': {\n",
    "                'Bucket': bucket,\n",
    "                'Name': prefix_uri\n",
    "            }\n",
    "        },\n",
    "        MaxLabels=5,\n",
    "    )\n",
    "    for label in response['Labels']:\n",
    "        print(\"Amazon Rekognition is \"+str(round(label['Confidence'],0))+\" confident that this picture is of a \"+label['Name'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is one API we tried for detecting labels. Rekognition has a host of other features and APIs you can use. Please refer to https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/rekognition.html"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Amazon Translate for machine translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an output translations directory\n",
    "dr = os.getcwd()+'/output-translations'\n",
    "if not os.path.exists(dr):\n",
    "    os.makedirs(dr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Please make sure you have executed the Amazon Transcribe section above before your come here\n",
    "# Let us use the transcribed list we created before\n",
    "x = 0\n",
    "translate_out = 'output-translations/translations.txt'\n",
    "t_list = []\n",
    "# the lines list here was created when we executed the Transcribe code sample earlier in this notebook. \n",
    "# It contains lines of transcribed text\n",
    "for line in lines:\n",
    "    x += 1\n",
    "    if (x % 2) == 0:\n",
    "        result = translate.translate_text(Text=line, SourceLanguageCode='auto', TargetLanguageCode='hi')\n",
    "    else:\n",
    "        result = translate.translate_text(Text=line, SourceLanguageCode='auto', TargetLanguageCode='fr')\n",
    "    t_list.append(\"Line \"+str(x)+\": \"+result['TranslatedText'])\n",
    "with open(translate_out, 'w') as t_out:\n",
    "    t_out.write(str(t_list))\n",
    "# print the translation results\n",
    "for l in t_list:\n",
    "    print(l)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# view the contents of our output file\n",
    "!cat output-translations/translations.txt"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Amazon Polly for text to speech"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "input_text = \"I think AI and ML are the most popular skills right now, and I am glad I brought this book. It helps me learn how to build real-world and large scale AI and ML applications on Amazon Web Services. I loved the breadth and depth of coverage on the ML workflow, on using the various features of Amazon SageMaker, and the AI services that made powerful ML models available behind simple API calls. Overall this books is a very good learning resource\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create an output directory\n",
    "dr = os.getcwd()+'/output-audio'\n",
    "if not os.path.exists(dr):\n",
    "    os.makedirs(dr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "response = polly.synthesize_speech(VoiceId='Kajal',\n",
    "                OutputFormat='mp3', \n",
    "                Text = input_text,\n",
    "                Engine = 'neural')\n",
    "\n",
    "mp3_file = open('./output-audio/chapter10-polly-test.mp3', 'wb')\n",
    "mp3_file.write(response['AudioStream'].read())\n",
    "mp3_file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls output-audio"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Play the audio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import Audio\n",
    "Audio('./output-audio/chapter10-polly-test.mp3', autoplay=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Using Amazon Comprehend for deriving insights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For Comprehend we will take the Transcript output and see what insights we can get from this text\n",
    "transcript = 'output-transcripts/'+job+'.txt'\n",
    "print(transcript)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the contents of the transcript into a text\n",
    "with open(transcript, 'r') as comp_in:\n",
    "    in_text = comp_in.read().split(',')\n",
    "# lets re-construct a full text from the list of sentences\n",
    "full_text = ''\n",
    "for text in in_text:\n",
    "    full_text += text+'. '"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Detect Entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "comp_res = comprehend.detect_entities(Text=full_text, LanguageCode='en')\n",
    "for entity in comp_res['Entities']:\n",
    "    print(\"Comprehend is \"+str(round(entity['Score']*100,0))+\"% confident that \"+entity['Text']+\" is an entity of type \"+entity['Type']+\" \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Detect Keyphrases\n",
    "These are important groups of words within text that when read together provide a relevant summarization of the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Read and print the key phrases\n",
    "comp_res = comprehend.detect_key_phrases(Text=full_text, LanguageCode='en')\n",
    "for phrase in comp_res['KeyPhrases']:\n",
    "    print(\"Comprehend is \"+str(round(phrase['Score']*100,0))+\"% confident that \"+phrase['Text']+\" is a key phrase\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Detect Sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sent_text = 'Also if you wanted to wait for the two days we could also have a rental car available for you at no charge in case you wanted that in case it takes a little bit longer to fix that will be an option that we can plan out for you as well but again you are also welcome to come in any time before then and we will get you in as soon as we can'\n",
    "comp_res = comprehend.detect_sentiment(Text=sent_text, LanguageCode='en')\n",
    "print(comp_res['Sentiment'])\n",
    "print(comp_res['SentimentScore'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Detect Syntax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "synt_text = 'Also if you wanted to wait for the two days we could get a rental car'\n",
    "comp_res = comprehend.detect_syntax(Text=synt_text, LanguageCode='en')\n",
    "for token in comp_res['SyntaxTokens']:\n",
    "    print(\"The Part of Speech for word: \"+token['Text']+\" :is: \"+token['PartOfSpeech']['Tag'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For a full list of Comprehend APIs please refer to https://boto3.amazonaws.com/v1/documentation/api/latest/reference/services/comprehend.html#comprehend"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### END OF NOTEBOOK\n",
    "Please refer to Chapter 10 in the book for further instructions"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
