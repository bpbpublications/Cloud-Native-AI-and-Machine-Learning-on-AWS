{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import io\n",
    "import os\n",
    "import time\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import sagemaker\n",
    "import sagemaker.amazon.common as smac\n",
    "from sagemaker.amazon.amazon_estimator import RecordSet\n",
    "from sagemaker import get_execution_role\n",
    "\n",
    "# Enter the name of the bucket you used in Chapter 4 here\n",
    "bucket = 'bucket-name-from-Chapter4'\n",
    "prefix = 'aiml-book/chapter4/glue-out/'\n",
    "s3 = boto3.client('s3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download the scaled CSV file we created in Chapter 4\n",
    "s3.download_file(bucket, prefix+'wine_scaled.csv','wine_scaled.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's first load the data into a Pandas dataframe so it is easy for us to work with it\n",
    "wine_scaled_df = pd.read_csv('./wine_scaled.csv', sep=',',header=0)\n",
    "wine_scaled_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# display the first few rows\n",
    "wine_scaled_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we have our data, lets get rid of the country columns and select a thousand rows to make it more understandable\n",
    "wine_alg_df = wine_scaled_df.iloc[0:1000,0:6]\n",
    "wine_alg_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "col_ord = ['price','points','last_year_points','designation_freq','winery_freq','variety_transformed']\n",
    "# reorder to move label (we want to predict the price of the wine) to first position\n",
    "wine_alg_ord_df = wine_alg_df.reindex(columns=col_ord)\n",
    "wine_alg_ord_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will now use a couple of methods to **train a regression model to predict the price for a bottle of wine** based on points, last years points, winery, designation and grape variety features that we engineered in Chapters 3 and 4 of the book"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm 1 - Linear Learner\n",
    "#### Algorithm Type = Statistical/Math Function\n",
    "#### ML use case = Regressor\n",
    "#### ML topic = Tabular data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need the IAM role from our notebook to run our training job\n",
    "role = get_execution_role()\n",
    "print(role)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split our dataset into train and validation datasets in prep for model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "split_list = np.random.rand(wine_alg_ord_df.shape[0])\n",
    "t_list = split_list < 0.9\n",
    "v_list = split_list >= 0.9\n",
    "\n",
    "train_ds = wine_alg_ord_df[t_list]\n",
    "val_ds = wine_alg_ord_df[v_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we extract the label and input features for both training and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_label = train_ds.iloc[:, 0].to_numpy()\n",
    "train_features = train_ds.iloc[:, 1:].to_numpy()\n",
    "\n",
    "val_label = val_ds.iloc[:, 0].to_numpy()\n",
    "val_features = val_ds.iloc[:, 1:].to_numpy()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### IMPORTANT - We are using a m5.xlarge instance here to run our training, this will incur costs to your AWS account"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the linear learner estimator and specify hyperparameters\n",
    "estimator = sagemaker.LinearLearner(\n",
    "    role=role,\n",
    "    instance_count=1,\n",
    "    instance_type=\"ml.m5.xlarge\",\n",
    "    predictor_type=\"regressor\",\n",
    "    epochs=10,\n",
    "    loss=\"squared_loss\",\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Convert our datasets into RecordSets as expected by SageMaker"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_records = estimator.record_set(train_features.astype(\"float32\"), train_label.astype(\"float32\"), channel=\"train\")\n",
    "val_records = estimator.record_set(val_features.astype(\"float32\"), val_label.astype(\"float32\"), channel=\"validation\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now start training by executing fit on our estimator object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "estimator.fit([train_records, val_records],mini_batch_size=50, wait=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Navigate to Amazon SageMaker console and click on Training Jobs on the left to check the status of your training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Algorithm 2 - Multi-layer Perceptron or MLP\n",
    "#### Algorithm Type = Neural Network\n",
    "#### ML Framework = Tensorflow\n",
    "#### ML use case = Regression\n",
    "#### ML topic = Tabular data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will reuse the train and validation features from our linear learner example above. We are trying to predict the price of wine based on input features such as points, winery, designation, and grape variety"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"training label shape is: \" + str(train_label.shape))\n",
    "print(\"training features shape is: \" + str(train_features.shape))\n",
    "print(\"validation label shape is: \" + str(val_label.shape))\n",
    "print(\"validation features shape is: \" + str(val_features.shape))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define the neural network architecture"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "# set up the neural network layer by layer with 5 neurons in 1st hidden layer\n",
    "# 3 neurons in second hidden layer\n",
    "# output is 1 neuron\n",
    "model = Sequential()\n",
    "model.add(Dense(5, activation='relu', kernel_initializer='random_normal', input_shape=(train_features.shape[1],)))\n",
    "model.add(Dense(3, activation='relu', kernel_initializer='random_normal'))\n",
    "model.add(Dense(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile and fit the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will use the mean squared error as the calculated loss between the label and predictions\n",
    "# the model will try to minimize this loss during training\n",
    "# we will use the stochastic gradient descent as the optimizer method for learning\n",
    "model.compile(optimizer='sgd', loss='mse')\n",
    "# fit the model\n",
    "model.fit(train_features.astype(\"float32\"), train_label.astype(\"float32\"), epochs=25, batch_size=50)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "val_results = model.evaluate(val_features.astype(\"float32\"), val_label.astype(\"float32\"))\n",
    "print('Root Mean Squared Error or RMSE is: ' + str(math.sqrt(val_results)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The section below is optional in case you want to learn a different method to set up training in SageMaker"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### OPTIONAL - Training using Create Training Job SageMaker API"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create RecordIO protobuf format of our dataset for faster training performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_file = \"train.data\"\n",
    "\n",
    "linear_prefix = 'aiml-book/chapter5/linear-learner'\n",
    "\n",
    "t_fil = io.BytesIO()\n",
    "smac.write_numpy_to_dense_tensor(t_fil, train_features.astype(\"float32\"), train_label.astype(\"float32\"))\n",
    "t_fil.seek(0)\n",
    "\n",
    "boto3.Session().resource(\"s3\").Bucket(bucket).Object(\n",
    "    os.path.join(linear_prefix, \"train\", t_file)\n",
    ").upload_fileobj(t_fil)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "v_file = \"validation.data\"\n",
    "\n",
    "linear_prefix = 'aiml-book/chapter5/linear-learner'\n",
    "\n",
    "v_fil = io.BytesIO()\n",
    "smac.write_numpy_to_dense_tensor(v_fil, train_features.astype(\"float32\"), train_label.astype(\"float32\"))\n",
    "v_fil.seek(0)\n",
    "\n",
    "boto3.Session().resource(\"s3\").Bucket(bucket).Object(\n",
    "    os.path.join(linear_prefix, \"validation\", v_file)\n",
    ").upload_fileobj(v_fil)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now get the linear learner algorithm image from SageMaker Elastic Container Repository"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sagemaker import image_uris\n",
    "\n",
    "container = image_uris.retrieve(region=boto3.Session().region_name, framework=\"linear-learner\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "*** IMPORTANT - We are using a m5.xlarge instance here to run our training, this will incur costs to your AWS account"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Specify training data and hyperparameters "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ll_train_job = \"Chapter5-linear-learner-\" + time.strftime(\"%Y-%m-%d-%H-%M-%S\", time.gmtime())\n",
    "\n",
    "print(\"Job name is:\", ll_train_job)\n",
    "\n",
    "ll_training = {\n",
    "    \"RoleArn\": role,\n",
    "    \"TrainingJobName\": ll_train_job,\n",
    "    \"AlgorithmSpecification\": {\"TrainingImage\": container, \"TrainingInputMode\": \"File\"},\n",
    "    \"ResourceConfig\": {\"InstanceCount\": 1, \"InstanceType\": \"ml.m5.xlarge\", \"VolumeSizeInGB\": 10},\n",
    "    \"InputDataConfig\": [\n",
    "        {\n",
    "            \"ChannelName\": \"train\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"S3DataType\": \"S3Prefix\",\n",
    "                    \"S3Uri\": \"s3://{}/{}/train/\".format(bucket, linear_prefix),\n",
    "                }\n",
    "            },\n",
    "        },\n",
    "        {\n",
    "            \"ChannelName\": \"validation\",\n",
    "            \"DataSource\": {\n",
    "                \"S3DataSource\": {\n",
    "                    \"S3DataType\": \"S3Prefix\",\n",
    "                    \"S3Uri\": \"s3://{}/{}/validation/\".format(bucket, linear_prefix),\n",
    "                }\n",
    "            },\n",
    "        },\n",
    "    ],\n",
    "    \"OutputDataConfig\": {\"S3OutputPath\": \"s3://{}/{}/\".format(bucket, linear_prefix)},\n",
    "    \"HyperParameters\": {\n",
    "        \"feature_dim\": \"auto\",\n",
    "        \"mini_batch_size\": \"50\",\n",
    "        \"predictor_type\": \"regressor\",\n",
    "        \"epochs\": \"10\",\n",
    "        \"loss\": \"auto\",\n",
    "    },\n",
    "    \"StoppingCondition\": {\"MaxRuntimeInSeconds\": 60 * 60},\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Start Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "sagemaker = boto3.client(\"sagemaker\")\n",
    "\n",
    "sagemaker.create_training_job(**ll_training)\n",
    "\n",
    "status = sagemaker.describe_training_job(TrainingJobName=ll_train_job)[\"TrainingJobStatus\"]\n",
    "print(status)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Navigate to Amazon SageMaker console and click on Training Jobs on the left to check the status of your training"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### END OF NOTEBOOK, please return to Chapter 5 in the book to proceed further"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (TensorFlow 2.6 Python 3.8 GPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-east-1:081325390199:image/tensorflow-2.6-gpu-py38-cu112-ubuntu20.04-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
